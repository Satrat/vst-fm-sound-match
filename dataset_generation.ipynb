{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we generate and save datasets for training and validating deep learning models. Additionally, we create a small audio dataset for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spiegelib as spgl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dexed and set the note length and render length to be one second. For this experiment we aren’t worried about the release of the sound. To capture the release portion of a synth signal, set the render length to longer than the note length. We also reload the configuration previously saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = spgl.synth.SynthVST(\"/Library/Audio/Plug-Ins/Components/Dexed.component\", note_length_secs=1.0, render_length_secs=1.0)\n",
    "synth.load_state('./synth_params/dexed_simple_fm.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MFCC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training and testing dataset using Mel-frequency Cepstral Coefficients feature extraction. The DatasetGenerator class works by generating random patches from the synthesizer, then running audio feature extraction on the resulting sound, and then saving the audio features and parameter values. Audio features and parameter values are saved in separate .npy files.\n",
    "\n",
    "We set the time_major argument to True so that the orientation of the output is (time_slices, features), as opposed to (features, time_slices) which is default. This is how TensorFlow models expect the data to be oriented.\n",
    "\n",
    "The scale argument is set to True which causes the dataset to be scaled after feature extraction. Standardization is the scaling applied by default which removes the mean and scales to unit variance along each feature. The settings for this scaling are set based on the first training dataset, and then re-used on the testing dataset and on future data.\n",
    "\n",
    "The total size of this dataset is about 140MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = spgl.features.MFCC(num_mfccs=13, frame_size=2048, hop_size=1024, time_major=True)\n",
    "generator = spgl.DatasetGenerator(synth, features,\n",
    "                                  output_folder=\"./data_simple_FM_mfcc\",\n",
    "                                  scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Dataset: 100%|██████████| 1000/1000 [00:20<00:00, 49.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting scaler and scaling data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Dataset: 100%|██████████| 100/100 [00:02<00:00, 45.97it/s]\n"
     ]
    }
   ],
   "source": [
    "generator.generate(1000, file_prefix=\"train_\")\n",
    "generator.generate(100, file_prefix=\"test_\")\n",
    "generator.save_scaler('data_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STFT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training and testing dataset using the magnitude of the STFT. This dataset will be used to train the convolutional neural network. \n",
    "\n",
    "The total size of the resulting dataset is about 10.8GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commenting this section out for now, limited disk space...\n",
    "\n",
    "# Magnitude STFT ouptut feature extraction\n",
    "#features = spgl.features.STFT(fft_size=512, hop_size=256, output='magnitude', time_major=True)\n",
    "\n",
    "# Setup generator and create dataset\n",
    "#generator = spgl.DatasetGenerator(synth, features, output_folder=\"./data_simple_FM_stft\", scale=True)\n",
    "#generator.generate(50000, file_prefix=\"train_\")\n",
    "#generator.generate(10000, file_prefix=\"test_\")\n",
    "#generator.save_scaler('data_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an audio set for evaluation. We set the save_audio argument to True in the DatasetGenerator constructor so that audio WAV files are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Dataset: 100%|██████████| 25/25 [00:00<00:00, 47.26it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_generator = spgl.DatasetGenerator(synth, features,\n",
    "                                       output_folder='./evaluation',\n",
    "                                       save_audio=True)\n",
    "eval_generator.generate(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
