{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform sound matching of the evaluation target set using the trained deep learning models and save the resulting audio files to disk for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spiegel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all saved models\n",
    "mlp = spiegel.estimator.TFEstimatorBase.load('./saved_models/simple_fm_mlp.h5')\n",
    "lstm = spiegel.estimator.TFEstimatorBase.load('./saved_models/simple_fm_lstm.h5')\n",
    "bi_lstm = spiegel.estimator.TFEstimatorBase.load('./saved_models/simple_fm_bi_lstm.h5')\n",
    "cnn = spiegel.estimator.TFEstimatorBase.load('./saved_models/simple_fm_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load synth with overriden params\n",
    "synth = spiegel.synth.SynthVST(\"/Library/Audio/Plug-Ins/VST/Dexed.vst\",\n",
    "                               note_length_secs=1.0, render_length_secs=1.0)\n",
    "synth.load_state(\"./synth_params/dexed_simple_fm.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup all the feature extractors to provide the correct input data for each model based on how it was trained. Also use the same data normalizers that were setup during data creation and were used for training each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP feature extractor with a modifying function that flattens the time slice arrays at the end of the feature\n",
    "# extraction pipeline\n",
    "mlp_extractor = spiegel.features.MFCC(num_mfccs=13, time_major=True, hop_size=1024, normalize=True)\n",
    "mlp_extractor.load_normalizers('./data_simple_fm_mfcc/normalizers.pkl')\n",
    "mlp_extractor.add_modifier(lambda data : data.flatten(), type='output')\n",
    "\n",
    "# LSTM & LSTM++ feature extractor -- time series of MFCC frames\n",
    "lstm_extractor = spiegel.features.MFCC(num_mfccs=13, time_major=True, hop_size=1024, normalize=True)\n",
    "lstm_extractor.load_normalizers('./data_simple_fm_mfcc/normalizers.pkl')\n",
    "\n",
    "# CNN feature extractor uses magnitude output from STFT and then modifies the output array into a 3D array for the\n",
    "# 2D convolutional network becuase it is expecting an image with a single channel (ie grayscale).\n",
    "cnn_extractor = spiegel.features.MagnitudeSTFT(fft_size=512, hop_size=256, time_major=True, normalize=True)\n",
    "cnn_extractor.load_normalizers('./data_simple_fm_stft/normalizers.pkl')\n",
    "cnn_extractor.add_modifier(lambda data : data.reshape(data.shape[0], data.shape[1], 1), type='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sound match instances for each of the deep learning models to run on the loaded Dexed Synth using the feature extractors created specific for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_matcher = spiegel.SoundMatch(synth, mlp, mlp_extractor)\n",
    "lstm_matcher = spiegel.SoundMatch(synth, lstm, lstm_extractor)\n",
    "bi_lstm_matcher = spiegel.SoundMatch(synth, bi_lstm, lstm_extractor)\n",
    "cnn_matcher = spiegel.SoundMatch(synth, cnn, cnn_extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the folder of evaluation audio samples and perform sound matching on each one with each estimation model. AudioBuffer.load_folder performs a natural sort based on the file names of the audio contained in the specified folder, so we can save each prediction with a corresponding integer number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = spiegel.AudioBuffer.load_folder('./evaluation/audio')\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    audio = mlp_matcher.match(targets[i])\n",
    "    audio.save('./evaluation/mlp/mlp_prediction_%s.wav' % i)\n",
    "\n",
    "    audio = lstm_matcher.match(targets[i])\n",
    "    audio.save('./evaluation/lstm/lstm_prediction_%s.wav' % i)\n",
    "\n",
    "    audio = bi_lstm_matcher.match(targets[i])\n",
    "    audio.save('./evaluation/bi_lstm/bi_lstm_prediction_%s.wav' % i)\n",
    "\n",
    "    audio = cnn_matcher.match(targets[i])\n",
    "    audio.save('./evaluation/cnn/cnn_prediction_%s.wav' % i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
